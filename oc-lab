#!/bin/bash

# Function to display usage information
usage() {
  echo "Usage: --create --name <name_of_cluster> [--workers <number_of_worker_nodes>] [--airgap]"
  echo "       --destroy --name <name_of_cluster>"
  echo "       --status --name <name_of_cluster>"
  echo "       --start --name <name_of_cluster>"
  echo "       --stop --name <name_of_cluster>"
  echo "       --attach --name <name_of_cluster> --iso <path_to_iso>"
  echo "       --generate-agentconfig --name <name_of_cluster>"
  echo "       --generate-installconfig --name <name_of_cluster>"
  echo ""
  echo "Commands:"
  echo "  --create              Create a new cluster"
  echo "  --destroy             Destroy an existing cluster"
  echo "  --status              Check the status of the VMs"
  echo "  --start               Start all the VMs"
  echo "  --stop                Stop all the VMs"
  echo "  --attach              Attach an ISO image to all the VMs"
  echo "  --generate-agentconfig Generate AgentConfig for the cluster"
  echo "  --generate-installconfig Generate InstallConfig for the cluster"
  echo ""
  echo "Options:"
  echo "  --name, -n            Name of the cluster (required)"
  echo "  --workers             Number of worker nodes (default is 2)"
  echo "  --airgap              Disconnect the network from the internet (default is connected)"
  echo "  --iso                 Path to the ISO image (required for --attach)"
  echo "  --type                Type of cluster (compact or virt)"
  exit 1
}

# Default values
WORKERS=2
AIRGAP="false"
COMMAND=""
CLUSTER_NAME=""
ISO_PATH=""
DOMAIN_NAME="superdemo.live"
TYPE=""

# Parse command-line arguments
while [[ "$#" -gt 0 ]]; do
  case "$1" in
    --create)
      COMMAND="create"
      ;;
    --destroy)
      COMMAND="destroy"
      ;;
    --status)
      COMMAND="status"
      ;;
    --start)
      COMMAND="start"
      ;;
    --stop)
      COMMAND="stop"
      ;;
    --attach)
      COMMAND="attach"
      ;;
    --generate-agentconfig)
      COMMAND="generate-agentconfig"
      ;;
     --generate-installconfig)
      COMMAND="generate-installconfig"
      ;;
    --name|-n)
      CLUSTER_NAME="$2"
      shift
      ;;
    --domain|-d)
      DOMAIN_NAME="$2"
      shift
      ;;
    --workers)
      WORKERS="$2"
      shift
      ;;
    --airgap)
      AIRGAP="true"
      ;;
    --iso)
      ISO_PATH="$2"
      shift
      ;;
    --type)
      TYPE="$2"
      shift
      ;;
    *)
      usage
      ;;
  esac
  shift
done

# Check for required arguments
if [ -z "${COMMAND}" ] || [ -z "${CLUSTER_NAME}" ]; then
  usage
fi

if [ "${COMMAND}" == "attach" ] && [ -z "${ISO_PATH}" ]; then
  usage
fi

generate_network_xml() {
  local cluster_name=$1
  local domain=$2
  local forward_mode="nat"

  if [ "${AIRGAP}" == "true" ]; then
    forward_mode="route"
  fi

  cat <<EOF
<network xmlns:dnsmasq='http://libvirt.org/schemas/network/dnsmasq/1.0'>
  <name>${cluster_name}</name>
  <bridge name='${cluster_name}' stp='on' delay='0'/>
  <forward mode='${forward_mode}'/>
  <domain name='${domain}' localOnly='yes'/>
  <dns>
    <host ip='10.101.194.2'>
      <hostname>quay.${cluster_name}.${domain}</hostname>
    </host>
    <host ip='10.101.194.5'>
      <hostname>api.${cluster_name}.${domain}</hostname>
    </host>
  </dns>
  <ip address='10.101.194.1' netmask='255.255.255.0'>
    <dhcp>
      <range start='10.101.194.100' end='10.101.194.200'/>
    </dhcp>
  </ip>
  <ip address='10.101.194.2' netmask='255.255.255.0'/>
  <ip address='10.101.194.3' netmask='255.255.255.0'/>
  <dnsmasq:options>
    <dnsmasq:option value='address=/.apps.${cluster_name}.${domain}/10.101.194.10'/>
  </dnsmasq:options>
</network>
EOF
}

generate_mac_address() {
  printf '52:54:00:%02x:%02x:%02x\n' $((RANDOM % 256)) $((RANDOM % 256)) $((RANDOM % 256))
}

create_vm() {
  local VM_NAME=$1
  local NET_NAME=$4
  local DISK_PATH="/var/lib/libvirt/images/${VM_NAME}.qcow2"
  local DISK_PATH_ODF="/var/lib/libvirt/images/${VM_NAME}_odf.qcow2"
  local RAM=$2
  local VCPUS=$3
  local MAC1=$(generate_mac_address)

  # Create a disk image
  qemu-img create -f qcow2 ${DISK_PATH} 120G &>/dev/null
  qemu-img create -f qcow2 ${DISK_PATH_ODF} 1T &>/dev/null

  # Define the VM using a direct XML template
  cat <<EOF > ${VM_NAME}.xml
<domain type="kvm">
  <name>${VM_NAME}</name>
  <memory unit="KiB">${RAM}</memory>
  <currentMemory unit="KiB">${RAM}</currentMemory>
  <vcpu>${VCPUS}</vcpu>
  <os>
    <type arch="x86_64" machine="q35">hvm</type>
    <boot dev="hd"/>
    <boot dev='cdrom'/>
  </os>
  <features>
    <acpi/>
    <apic/>
  </features>
  <cpu mode="host-passthrough"/>
  <clock offset="utc">
    <timer name="rtc" tickpolicy="catchup"/>
    <timer name="pit" tickpolicy="delay"/>
    <timer name="hpet" present="no"/>
  </clock>
  <devices>
    <emulator>/usr/libexec/qemu-kvm</emulator>
    <disk type="file" device="disk">
      <driver name="qemu" type="qcow2" discard="unmap"/>
      <source file="${DISK_PATH}"/>
      <target dev="sda" bus="scsi"/>
    </disk>
    <disk type="file" device="disk">
      <driver name="qemu" type="qcow2" discard="unmap"/>
      <source file="${DISK_PATH_ODF}"/>
      <target dev="sdb" bus="scsi"/>
    </disk>
    <disk type='block' device='cdrom'>
        <driver name='qemu' type='raw'/>
        <target dev='hdd' bus='scsi' tray='open'/>
        <readonly/>
    </disk>
    <controller type="usb" model="qemu-xhci" ports="15"/>
    <controller type="scsi" model="virtio-scsi"/>
    <controller type="pci" model="pcie-root"/>
    <controller type="pci" model="pcie-root-port"/>
    <interface type="bridge">
      <source bridge="${NET_NAME}"/>
      <mac address="${MAC1}"/>
      <model type="virtio"/>
    </interface>
    <console type="pty">
      <target type="serial"/>
    </console>
    <channel type="unix">
      <source mode="bind"/>
      <target type="virtio" name="org.qemu.guest_agent.0"/>
    </channel>
    <input type="tablet" bus="usb"/>
    <graphics type="vnc" port="-1"/>
    <video>
      <model type="virtio"/>
    </video>
    <memballoon model="virtio"/>
    <rng model="virtio">
      <backend model="random">/dev/urandom</backend>
    </rng>
  </devices>
</domain>
EOF

  # Define the VM using the XML file
  virsh define ${VM_NAME}.xml &>/dev/null && rm ${VM_NAME}.xml
}

start_vms() {
  for VM in $(virsh list --all --name | grep "${CLUSTER_NAME}-"); do
    virsh start ${VM} &>/dev/null
  done
  echo "All VMs in the cluster ${CLUSTER_NAME} have been started."
}

stop_vms() {
  for VM in $(virsh list --all --name | grep "${CLUSTER_NAME}-"); do
    virsh destroy ${VM} &>/dev/null
  done
  echo "All VMs in the cluster ${CLUSTER_NAME} have been stopped."
}

attach_iso() {
  for VM in $(virsh list --all --name | grep "${CLUSTER_NAME}-"); do
    virsh change-media ${VM} hdd ${ISO_PATH} --insert --config &>/dev/null
  done
  echo "ISO image ${ISO_PATH} has been attached to all VMs in the cluster ${CLUSTER_NAME}."
}

check_status() {
  for VM in $(virsh list --all --name | grep "${CLUSTER_NAME}-"); do
    STATUS=$(virsh domstate ${VM})
    echo "${VM} is ${STATUS}"
  done
}

create_cluster() {

  # Handle different types
  if [ "${TYPE}" == "compact" ]; then
    WORKERS=0
    MASTER_RAM=16777216  # 16 GB
    MASTER_VCPUS=4
  elif [ "${TYPE}" == "virt" ]; then
    WORKERS=0
    MASTER_RAM=33554432  # 32 GB
    MASTER_VCPUS=8
  else
    MASTER_RAM=16777216  # 16 GB
    MASTER_VCPUS=4
  fi
  
  # Generate and define the network XML
  NETWORK_XML=$(generate_network_xml ${CLUSTER_NAME} ${DOMAIN_NAME})
  echo "${NETWORK_XML}" | virsh net-define /dev/stdin &>/dev/null

  # Start and autostart the network
  virsh net-start ${CLUSTER_NAME} &>/dev/null
  virsh net-autostart ${CLUSTER_NAME} &>/dev/null

  # Validate the network is active
  if ! virsh net-info ${CLUSTER_NAME} &>/dev/null; then
    echo "Failed to create and start the network ${CLUSTER_NAME}."
    exit 1
  fi

  # Create master VMs
  for ((i=1; i<=3; i++)); do
    VM_NAME="master-${CLUSTER_NAME}-$(printf "%02d" ${i})"
    create_vm ${VM_NAME} ${MASTER_RAM} ${MASTER_VCPUS} ${CLUSTER_NAME}
  done

  # Create worker VMs
  for ((i=1; i<=WORKERS; i++)); do
    VM_NAME="worker-${CLUSTER_NAME}-$(printf "%02d" ${i})"
    create_vm ${VM_NAME} 8388608 2 ${CLUSTER_NAME}
  done

  echo "Cluster Name: ${CLUSTER_NAME}"
  echo "Number of Worker VMs: ${WORKERS}"
  echo "VMs:"

  # Output VM details
  for ((i=1; i<=3; i++)); do
    VM_NAME="master-${CLUSTER_NAME}-$(printf "%02d" ${i})"
    if virsh dominfo ${VM_NAME} &>/dev/null; then
      MAC_ADDRESS=$(virsh dumpxml ${VM_NAME} | grep "mac address" | awk -F\' '{ print $2 }')
      UUID=$(virsh dominfo ${VM_NAME} | grep 'UUID' | awk '{print $2}')
      echo "  - Name: ${VM_NAME}, MAC Address: ${MAC_ADDRESS}, UUID: ${UUID}"
    else
      echo "  - Name: ${VM_NAME} creation failed."
    fi
  done

  for ((i=1; i<=WORKERS; i++)); do
    VM_NAME="worker-${CLUSTER_NAME}-$(printf "%02d" ${i})"
    if virsh dominfo ${VM_NAME} &>/dev/null; then
      MAC_ADDRESS=$(virsh dumpxml ${VM_NAME} | grep "mac address" | awk -F\' '{ print $2 }')
      UUID=$(virsh dominfo ${VM_NAME} | grep 'UUID' | awk '{print $2}')
      echo "  - Name: ${VM_NAME}, MAC Address: ${MAC_ADDRESS}, UUID: ${UUID}"
    else
      echo "  - Name: ${VM_NAME} creation failed."
    fi
  done
}

destroy_cluster() {

  # Destroy and undefine VMs
  for VM_NAME in $(virsh list --all --name | grep "${CLUSTER_NAME}-"); do
    virsh destroy ${VM_NAME} &>/dev/null
    virsh undefine ${VM_NAME} &>/dev/null
    rm -f /var/lib/libvirt/images/${VM_NAME}.qcow2
    rm -f /var/lib/libvirt/images/${VM_NAME}_odf.qcow2
  done

# Destroy and undefine network
  virsh net-destroy ${CLUSTER_NAME} &>/dev/null
  virsh net-undefine ${CLUSTER_NAME} &>/dev/null

  echo "Cluster ${CLUSTER_NAME} destroyed."
}

generate_agent_config() {
  local WORKERS=$(virsh list --all --name | grep "worker-" | wc -l)
  local base_ip_test=$(getent hosts "api.${CLUSTER_NAME}.${DOMAIN_NAME}" | awk '{ print $1 }')

  # Check if the base_ip is empty or not resolved
  if [ -z "${base_ip_test}" ]; then
    echo "Failed to resolve DNS for api.${CLUSTER_NAME}.${DOMAIN_NAME}. Please verify DNS configuration."
    exit 1
  fi

  local base_ip=$(echo "${base_ip_test}" | awk -F '.' '{print $1"."$2"."$3""}')

  echo "apiVersion: v1alpha1"
  echo "kind: AgentConfig"
  echo "metadata:"
  echo "  name: ${CLUSTER_NAME}"
  echo "rendezvousIP: ${base_ip}.20"
  echo "hosts:"
  # Generate master nodes configurations
  for i in {1..3}; do
    local ip=$((19+i))
    local mac=$(virsh dumpxml master-${CLUSTER_NAME}-$(printf "%02d" $i) | grep "mac address" | awk -F\' '{ print $2 }')
    echo "- hostname: master${i}"
    echo "  role: master"
    echo "  interfaces:"
    echo "  - macAddress: ${mac}"
    echo "    name: enp1s0"
    echo "  networkConfig:"
    echo "    dns-resolver:"
    echo "      config:"
    echo "        server:"
    echo "        - ${base_ip}.1"
    echo "    interfaces:"
    echo "    - ipv4:"
    echo "        address:"
    echo "        - ip: ${base_ip}.${ip}"
    echo "          prefix-length: 24"
    echo "        dhcp: false"
    echo "        enabled: true"
    echo "      mac-address: ${mac}"
    echo "      name: enp1s0"
    echo "      state: up"
    echo "      type: ethernet"
    echo "    routes:"
    echo "      config:"
    echo "      - destination: 0.0.0.0/0"
    echo "        next-hop-address: ${base_ip}.1"
    echo "        next-hop-interface: enp1s0"
    echo "        table-id: 254"
  done

  # Generate worker nodes configurations based on the WORKERS variable
  for ((i=1; i<=WORKERS; i++)); do
    local ip=$((29+i))
    local mac=$(virsh dumpxml worker-${CLUSTER_NAME}-$(printf "%02d" $i) | grep "mac address" | awk -F\' '{ print $2 }')
    echo "- hostname: worker${i}"
    echo "  role: worker"
    echo "  interfaces:"
    echo "  - macAddress: ${mac}"
    echo "    name: enp1s0"
    echo "  networkConfig:"
    echo "    dns-resolver:"
    echo "      config:"
    echo "        server:"
    echo "        - ${base_ip}.1"
    echo "    interfaces:"
    echo "    - ipv4:"
    echo "        address:"
    echo "        - ip: ${base_ip}.${ip}"
    echo "          prefix-length: 24"
    echo "        dhcp: false"
    echo "        enabled: true"
    echo "      mac-address: ${mac}"
    echo "      name: enp1s0"
    echo "      state: up"
    echo "      type: ethernet"
    echo "    routes:"
    echo "      config:"
    echo "      - destination: 0.0.0.0/0"
    echo "        next-hop-address: ${base_ip}.1"
    echo "        next-hop-interface: enp1s0"
    echo "        table-id: 254"
  done
}

generate_install_config() {
  if [ -z "$SSL_CERT_DIR" ]; then
    echo "SSL_CERT_DIR is not set. Please set the SSL_CERT_DIR environment variable to the directory containing your Quay certificates."
    exit 1
  fi
  local WORKERS=$(virsh list --all --name | grep "worker-" | wc -l)
  local base_domain=${DOMAIN_NAME}
  local cluster_name=${CLUSTER_NAME}
  local api_vip=$(getent hosts "api.${cluster_name}.${base_domain}" | awk '{ print $1 }')

  # Check if the api_vip is empty or not resolved
  if [ -z "${api_vip}" ]; then
    echo "Failed to resolve API VIP DNS for api.${cluster_name}.${base_domain}. Please verify DNS configuration."
    exit 1
  fi

  local ingress_vip=$(getent hosts "demo.apps.${cluster_name}.${base_domain}" | awk '{ print $1 }')
  local pull_secret=$(jq -c . $HOME/pull-secret.txt)
  local trust_bundle=$(cat ${SSL_CERT_DIR}/rootCA.pem | sed 's/^/    /')
  local machine_network_cidr=$(echo "${api_vip}" | awk -F '.' '{print $1"."$2"."$3".0/24"}')

  echo "apiVersion: v1"
  echo "baseDomain: ${base_domain}"
  echo "metadata:"
  echo "  name: ${cluster_name}"
  echo "networking:"
  echo "  clusterNetwork:"
  echo "  - cidr: 10.128.0.0/14"
  echo "    hostPrefix: 23"
  echo "  machineNetwork:"
  echo "  - cidr: ${machine_network_cidr}"
  echo "  networkType: OVNKubernetes"
  echo "  serviceNetwork:"
  echo "  - 172.30.0.0/16"
  echo "compute:"
  echo "  - architecture: amd64"
  echo "    hyperthreading: Enabled"
  echo "    name: worker"
  echo "    replicas: ${WORKERS}"
  echo "controlPlane:"
  echo "  architecture: amd64"
  echo "  hyperthreading: Enabled"
  echo "  name: master"
  echo "  replicas: 3"
  echo "platform:"
  echo "  baremetal:"
  echo "    hosts:"
  for i in {1..3}; do
    local mac=$(virsh dumpxml master-${cluster_name}-$(printf "%02d" $i) | grep "mac address" | awk -F\' '{ print $2 }')
    echo "    - name: master${i}"
    echo "      role: master"
    echo "      bootMACAddress: ${mac}"
  done
  for ((i=1; i<=WORKERS; i++)); do
    local mac=$(virsh dumpxml worker-${cluster_name}-$(printf "%02d" $i) | grep "mac address" | awk -F\' '{ print $2 }')
    echo "    - name: worker${i}"
    echo "      role: worker"
    echo "      bootMACAddress: ${mac}"
  done
  echo "    apiVIPs:"
  echo "    - ${api_vip}"
  echo "    ingressVIPs:"
  echo "    - ${ingress_vip}"
  echo "fips: false"
  echo "pullSecret: '${pull_secret}'"
  echo "imageContentSources:"
  echo "- mirrors:"
  echo "  - quay.${cluster_name}.${base_domain}:8443/openshift/release"
  echo "  source: quay.io/openshift-release-dev/ocp-v4.0-art-dev"
  echo "- mirrors:"
  echo "  - quay.${cluster_name}.${base_domain}:8443/openshift/release-images"
  echo "  source: quay.io/openshift-release-dev/ocp-release"
  echo "additionalTrustBundle: |"
  echo "${trust_bundle}"
}

if [ "${COMMAND}" == "create" ]; then
  create_cluster
elif [ "${COMMAND}" == "destroy" ]; then
  destroy_cluster
elif [ "${COMMAND}" == "status" ]; then
  check_status
elif [ "${COMMAND}" == "start" ]; then
  start_vms
elif [ "${COMMAND}" == "stop" ]; then
  stop_vms
elif [ "${COMMAND}" == "attach" ]; then
  attach_iso
# Add new option parsing for --generate-agentconfig
elif [ "${COMMAND}" == "generate-agentconfig" ]; then
  generate_agent_config
elif [ "${COMMAND}" == "generate-installconfig" ]; then
  generate_install_config
else
  usage
fi
